{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24d608fe-4635-4669-b4e2-cafadb41dc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53bf2bee-eb93-4c46-8479-b7f2329aad7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(network, img_shape, deep_tuning = False):\n",
    "    inputs = tf.keras.Input(shape=img_shape)\n",
    "\n",
    "    # Selecci칩n del modelo base\n",
    "    if network == 'vgg16':\n",
    "        base_model = tf.keras.applications.VGG16(input_tensor=inputs,\n",
    "                                                 include_top=False,\n",
    "                                                 weights='imagenet')\n",
    "    elif network == 'vgg19':\n",
    "        base_model = tf.keras.applications.VGG19(input_tensor=inputs,\n",
    "                                                 include_top=False,\n",
    "                                                 weights='imagenet')\n",
    "    elif network == 'resnet50':\n",
    "        base_model = tf.keras.applications.ResNet50(input_tensor=inputs,\n",
    "                                                    include_top=False,\n",
    "                                                    weights='imagenet')\n",
    "    elif network == 'inceptionv3':\n",
    "        base_model = tf.keras.applications.InceptionV3(input_tensor=inputs,\n",
    "                                                       include_top=False,\n",
    "                                                       weights='imagenet')\n",
    "    else:\n",
    "        raise ValueError(\"Solo 'vgg16', 'vgg19', 'resnet50' o 'inceptionv3' son v치lidos.\")\n",
    "\n",
    "    base_model.trainable = deep_tuning\n",
    "\n",
    "    # Adaptar arquitectura dependiendo de la red\n",
    "    if network =='inceptionv3':\n",
    "        x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "        x = tf.keras.layers.Dense(2048, activation='relu')(x)\n",
    "        x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    elif network =='resnet50':\n",
    "        x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "        x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    else:  # VGG16 y VGG19\n",
    "        x = tf.keras.layers.Flatten()(base_model.output)\n",
    "        x = tf.keras.layers.Dense(4096, activation='relu')(x)\n",
    "        x = tf.keras.layers.Dense(4096, activation='relu')(x)\n",
    "        x = tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "    # Capa de salida\n",
    "    outputs = tf.keras.layers.Dense(2, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    # model.summary()\n",
    "    return base_model, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ec747ec-4b1c-43e3-8f6e-6e475c6820e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Funci칩n de preprocesado para redes VGG16, VGG19 y ResNet50\n",
    "def preprocess_input1(x):\n",
    "  data_format = K.image_data_format()\n",
    "  assert data_format in {'channels_last', 'channels_first'}\n",
    "  if data_format == 'channels_first':\n",
    "      # 'RGB'->'BGR'\n",
    "      x = x[::-1, :, :]\n",
    "      # Zero-center by mean pixel\n",
    "\n",
    "      x[0, :, :] -= 103.939\n",
    "      x[1, :, :] -= 116.779\n",
    "      x[2, :, :] -= 123.68\n",
    "  else:\n",
    "      # 'RGB'->'BGR'\n",
    "      x = x[:, :, ::-1]\n",
    "      # Zero-center by mean pixel\n",
    "      x[:, :, 0] -= 103.939\n",
    "      x[:, :, 1] -= 116.779\n",
    "      x[:, :, 2] -= 123.68\n",
    "  return x\n",
    "\n",
    "# Funci칩n de preprocesado para redes InceptionV3 y Xception\n",
    "def preprocess_input2(x):\n",
    "  x /= 255.\n",
    "  x -= 0.5\n",
    "  x *= 2.\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8d86459-a8d1-4ffc-a0af-2582c67308be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from PIL import Image\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    class_names = [\"normal\", \"unhealthy\"]\n",
    "    \n",
    "    for class_name in class_names:\n",
    "        class_folder = os.path.join(folder, class_name)\n",
    "        if os.path.isdir(class_folder):\n",
    "            images = glob(os.path.join(class_folder, \"*.jpg\")) + glob(os.path.join(class_folder, \"*.png\"))\n",
    "            image_paths.extend(images)\n",
    "            labels.extend([0 if class_name == \"normal\" else 1] * len(images))  # Healthy = 0, Estrabismo = 1\n",
    "    \n",
    "    return image_paths, labels\n",
    "\n",
    "def load_image_array(path, img_size):\n",
    "    return np.array(\n",
    "        Image.open(path).convert(\"RGB\").resize((img_size, img_size)),\n",
    "        dtype=np.float32\n",
    "    )\n",
    "\n",
    "def set_data(network, img_size) :\n",
    "    # Cargar los conjuntos de datos\n",
    "    X_train, y_train = load_images_from_folder(\"kaggle-enrique-voluntarios/train\")\n",
    "    X_val, y_val = load_images_from_folder(\"kaggle-enrique-voluntarios/validation\")\n",
    "    X_test, y_test = load_images_from_folder(\"kaggle-enrique-voluntarios/test\")\n",
    "\n",
    "    # Sobrescribe X_* para que contengan arrays en lugar de rutas\n",
    "    X_train = [load_image_array(p, img_size) for p in X_train if os.path.isfile(p)]\n",
    "    X_val   = [load_image_array(p, img_size) for p in X_val   if os.path.isfile(p)]\n",
    "    X_test  = [load_image_array(p, img_size) for p in X_test  if os.path.isfile(p)]\n",
    "\n",
    "    # Preprocesar im치genes y filtrar errores\n",
    "    if (network == 'vgg16' or network == 'vgg19' or network == 'resnet50') :\n",
    "        print('Entrando en primer preprocesamiento')\n",
    "        X_train_preprocessed = np.array([img for img in (preprocess_input1(img) for img in X_train) if img is not None])\n",
    "        X_val_preprocessed   = np.array([img for img in (preprocess_input1(img) for img in X_val)   if img is not None])\n",
    "        X_test_preprocessed  = np.array([img for img in (preprocess_input1(img) for img in X_test)  if img is not None])\n",
    "    else :\n",
    "        print('Entrando en segundo preprocesamiento')\n",
    "        X_train_preprocessed = np.array([img for img in (preprocess_input2(img) for img in X_train) if img is not None])\n",
    "        X_val_preprocessed   = np.array([img for img in (preprocess_input2(img) for img in X_val)   if img is not None])\n",
    "        X_test_preprocessed  = np.array([img for img in (preprocess_input2(img) for img in X_test)  if img is not None])\n",
    "\n",
    "    # Verificar si hay im치genes perdidas\n",
    "    print(f\"游댳 Total im치genes en X_train: {X_train_preprocessed.shape}\")\n",
    "    print(f\"游댳 Total im치genes en X_val: {X_val_preprocessed.shape}\")\n",
    "    print(f\"游댳 Total im치genes en X_test: {X_test_preprocessed.shape}\")\n",
    "\n",
    "    # Convertir etiquetas a formato one-hot\n",
    "    num_classes = 2\n",
    "    y_train = to_categorical(y_train, num_classes=num_classes)\n",
    "    y_val = to_categorical(y_val, num_classes=num_classes)\n",
    "    y_test = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "    # Verificar formato final\n",
    "    print(f\"游댳 Etiquetas en formato one-hot (train): {y_train.shape}\")\n",
    "    print(f\"游댳 Etiquetas en formato one-hot (val): {y_val.shape}\")\n",
    "    print(f\"游댳 Etiquetas en formato one-hot (test): {y_test.shape}\")\n",
    "    \n",
    "    return X_train_preprocessed, y_train, X_val_preprocessed, y_val, X_test_preprocessed, y_test, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7175401-e08f-4bea-9480-431882b60c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "def train(model, network, model_name, X_train_preprocessed, y_train, X_val_preprocessed, y_val, epochs_number, use_data_augmentation=False):\n",
    "    # Callback para guardar el mejor modelo basado en la precisi칩n de validaci칩n\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        model_name,  # Nombre del archivo donde se guardar치 el mejor modelo\n",
    "        monitor=\"val_accuracy\",  # Monitoreamos la precisi칩n en validaci칩n\n",
    "        save_best_only=True,  # Guarda solo si es el mejor hasta el momento\n",
    "        mode=\"max\",  # Queremos la mayor precisi칩n posible\n",
    "        verbose=1  # Muestra mensajes cuando guarda un nuevo mejor modelo\n",
    "    )\n",
    "    \n",
    "    early_stop = EarlyStopping(\n",
    "        monitor=\"val_accuracy\",  # O puedes usar 'val_loss' si prefieres\n",
    "        patience=500,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\",\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        verbose=1,\n",
    "        min_lr=1e-7\n",
    "    )\n",
    "\n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.00001),  # cambio a 1e-4\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    if use_data_augmentation:\n",
    "        # Definir el generador de im치genes con Data Augmentation\n",
    "        datagen = ImageDataGenerator(\n",
    "            brightness_range=(0.8, 1.2),  # Ajusta el brillo entre 80% y 120% del original\n",
    "            # channel_shift_range=10.0,  # Cambia la intensidad de los colores en los canales RGB\n",
    "            rotation_range=10,  # Rota la imagen aleatoriamente hasta 15 grados\n",
    "            # zoom_range=0.1,  # Aplica zoom aleatorio en el rango de 80% a 120%\n",
    "            horizontal_flip=True,  # Invierte la imagen horizontalmente con probabilidad del 50%\n",
    "        )\n",
    "\n",
    "        datagen.fit(X_train_preprocessed)\n",
    "\n",
    "        # 4. Entrenamiento del modelo con `datagen.flow`\n",
    "        history = model.fit(\n",
    "            datagen.flow(X_train_preprocessed, y_train, batch_size=32),  # Generador de im치genes aumentado\n",
    "            epochs=epochs_number,\n",
    "            validation_data=(X_val_preprocessed, y_val),  # Validaci칩n sin aumento\n",
    "            verbose=1,\n",
    "            callbacks=callbacks_list,  # Usar el callback para guardar el modelo\n",
    "        )\n",
    "    else:\n",
    "        # Entrenamiento sin Data Augmentation\n",
    "        history = model.fit(\n",
    "            X_train_preprocessed, y_train,  # Usa directamente los datos preprocesados\n",
    "            batch_size=32,\n",
    "            epochs=epochs_number,\n",
    "            validation_data=(X_val_preprocessed, y_val),\n",
    "            verbose=1,\n",
    "            callbacks=[checkpoint]  # Agregar el callback aqu칤\n",
    "        )\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab0bcef6-0780-4073-87bc-ba5429b6532e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_metrics(history) :\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Extraer m칠tricas\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    accuracy = history.history['accuracy']\n",
    "    val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "\n",
    "    # Gr치fica de Loss\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, loss, 'bo-', label='Training Loss')\n",
    "    plt.plot(epochs, val_loss, 'ro-', label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    # Gr치fica de Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, accuracy, 'bo-', label='Training Accuracy')\n",
    "    plt.plot(epochs, val_accuracy, 'ro-', label='Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy over Epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef2db57e-ae7f-4a23-b05a-dac06e96879d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test_preprocessed, y_test) :\n",
    "    # Evaluar el modelo\n",
    "    test_loss, test_accuracy = model.evaluate(X_test_preprocessed, y_test, verbose=1)\n",
    "\n",
    "    # Imprimir los resultados\n",
    "    print(f\"Loss en el conjunto de prueba: {test_loss:.4f}\")\n",
    "    print(f\"Precisi칩n en el conjunto de prueba: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e22d30e0-8c7e-41d9-a29c-9d86a1c36578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "def save_model(model_name) :\n",
    "    model.save(f\"{model_name}.h5\")\n",
    "    model.save_weights(f\"{model_name}.weights.h5\")\n",
    "    print(f\"Saving model as {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8ff6335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.preprocessing import image\n",
    "# from tensorflow.keras.models import Model\n",
    "# import cv2\n",
    "\n",
    "# def get_last_conv_layer_name(model):\n",
    "#     for layer in reversed(model.layers):\n",
    "#         if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "#             return layer.name\n",
    "#     raise ValueError(\"No se encontr칩 una capa Conv2D.\")\n",
    "\n",
    "# def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "#     grad_model = Model(\n",
    "#         inputs=[model.inputs],\n",
    "#         outputs=[model.get_layer(last_conv_layer_name).output, model.output]\n",
    "#     )\n",
    "\n",
    "#     with tf.GradientTape() as tape:\n",
    "#         conv_outputs, predictions = grad_model(img_array)\n",
    "#         if pred_index is None:\n",
    "#             pred_index = tf.argmax(predictions[0])\n",
    "#         class_channel = predictions[:, pred_index]\n",
    "\n",
    "#     grads = tape.gradient(class_channel, conv_outputs)\n",
    "#     pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "#     conv_outputs = conv_outputs[0]\n",
    "#     heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
    "#     heatmap = tf.squeeze(heatmap)\n",
    "#     heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "#     return heatmap.numpy()\n",
    "\n",
    "# def save_and_display_gradcam(img_path, heatmap, alpha=0.4):\n",
    "#     img = cv2.imread(img_path)\n",
    "#     img = cv2.resize(img, (heatmap.shape[1], heatmap.shape[0]))\n",
    "#     heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "#     heatmap = np.uint8(255 * heatmap)\n",
    "#     heatmap_color = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "#     superimposed_img = cv2.addWeighted(img, 1 - alpha, heatmap_color, alpha, 0)\n",
    "    \n",
    "#     plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n",
    "#     plt.axis('off')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1db768a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import cv2\n",
    "# import tensorflow as tf\n",
    "# import matplotlib.pyplot as plt\n",
    "# import gc\n",
    "\n",
    "# networks = ['vgg16', 'vgg19', 'resnet50', 'inceptionv3']\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "# tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# for network in networks:\n",
    "#     print(f\"---------------{network}---------------\")\n",
    "    \n",
    "#     img_size = 299 if network == 'inceptionv3' else 224\n",
    "#     img_shape = (img_size, img_size, 3)\n",
    "#     print(img_size)\n",
    "\n",
    "#     base_model, model = build_model(network, img_shape)\n",
    "\n",
    "#     X_train_preprocessed, y_train, X_val_preprocessed, y_val, X_test_preprocessed, y_test, X_test = set_data(network, img_size)\n",
    "        \n",
    "#     is_data_augmentation = True\n",
    "#     model_name = f\"{network}_kaggle_enrique_voluntarios_2\"\n",
    "#     model, history = train(model, network, f'{model_name}.keras', X_train_preprocessed, y_train, X_val_preprocessed, y_val, 200, is_data_augmentation)\n",
    "    \n",
    "#     model.load_weights(f'{model_name}.keras')\n",
    "\n",
    "#     show_metrics(history)\n",
    "#     evaluate_model(model, X_test_preprocessed, y_test)\n",
    "#     save_model(model_name)\n",
    "\n",
    "#     # Limpiar memoria\n",
    "#     del model, base_model, history\n",
    "#     del X_train_preprocessed, y_train, X_val_preprocessed, y_val, X_test_preprocessed, y_test\n",
    "#     tf.keras.backend.clear_session()\n",
    "#     gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dec2d9-fa28-4c11-9c7d-4f090e160650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------vgg16---------------\n",
      "224\n",
      "Entrando en primer preprocesamiento\n",
      "游댳 Total im치genes en X_train: (475, 224, 224, 3)\n",
      "游댳 Total im치genes en X_val: (167, 224, 224, 3)\n",
      "游댳 Total im치genes en X_test: (159, 224, 224, 3)\n",
      "游댳 Etiquetas en formato one-hot (train): (475, 2)\n",
      "游댳 Etiquetas en formato one-hot (val): (167, 2)\n",
      "游댳 Etiquetas en formato one-hot (test): (159, 2)\n",
      "Train for 15 steps, validate on 167 samples\n",
      "Epoch 1/50\n",
      " 1/15 [=>............................] - ETA: 3:31"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-11-a9c9deb4b8aa>\", line 30, in <module>\n",
      "    model, history = train(model, network, f'{model_name}.keras', X_train_preprocessed, y_train, X_val_preprocessed, y_val, 50, is_data_augmentation)\n",
      "  File \"<ipython-input-5-c0d490c953fa>\", line 56, in train\n",
      "    callbacks=callbacks_list,  # Usar el callback para guardar el modelo\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 819, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 342, in fit\n",
      "    total_epochs=epochs)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 128, in run_one_epoch\n",
      "    batch_outs = execution_function(iterator)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\", line 98, in execution_function\n",
      "    distributed_function(input_fn))\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 568, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 632, in _call\n",
      "    return self._stateless_fn(*args, **kwds)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 2363, in __call__\n",
      "    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1611, in _filtered_call\n",
      "    self.captured_inputs)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1692, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager))\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 545, in call\n",
      "    ctx=ctx)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\", line 67, in quick_execute\n",
      "    six.raise_from(core._status_to_exception(e.code, message), None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "tensorflow.python.framework.errors_impl.ResourceExhaustedError:  OOM when allocating tensor with shape[32,128,112,112] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[node model/block2_conv2/Conv2D (defined at <ipython-input-5-c0d490c953fa>:56) ]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      " [Op:__inference_distributed_function_2147]\n",
      "\n",
      "Function call stack:\n",
      "distributed_function\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ResourceExhaustedError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-11-a9c9deb4b8aa>\", line 30, in <module>\n",
      "    model, history = train(model, network, f'{model_name}.keras', X_train_preprocessed, y_train, X_val_preprocessed, y_val, 50, is_data_augmentation)\n",
      "  File \"<ipython-input-5-c0d490c953fa>\", line 56, in train\n",
      "    callbacks=callbacks_list,  # Usar el callback para guardar el modelo\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 819, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 342, in fit\n",
      "    total_epochs=epochs)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 128, in run_one_epoch\n",
      "    batch_outs = execution_function(iterator)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\", line 98, in execution_function\n",
      "    distributed_function(input_fn))\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 568, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 632, in _call\n",
      "    return self._stateless_fn(*args, **kwds)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 2363, in __call__\n",
      "    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1611, in _filtered_call\n",
      "    self.captured_inputs)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1692, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager))\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 545, in call\n",
      "    ctx=ctx)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\", line 67, in quick_execute\n",
      "    six.raise_from(core._status_to_exception(e.code, message), None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "tensorflow.python.framework.errors_impl.ResourceExhaustedError:  OOM when allocating tensor with shape[32,128,112,112] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[node model/block2_conv2/Conv2D (defined at <ipython-input-5-c0d490c953fa>:56) ]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      " [Op:__inference_distributed_function_2147]\n",
      "\n",
      "Function call stack:\n",
      "distributed_function\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ResourceExhaustedError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3360, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1193, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-11-a9c9deb4b8aa>\", line 30, in <module>\n",
      "    model, history = train(model, network, f'{model_name}.keras', X_train_preprocessed, y_train, X_val_preprocessed, y_val, 50, is_data_augmentation)\n",
      "  File \"<ipython-input-5-c0d490c953fa>\", line 56, in train\n",
      "    callbacks=callbacks_list,  # Usar el callback para guardar el modelo\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 819, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 342, in fit\n",
      "    total_epochs=epochs)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 128, in run_one_epoch\n",
      "    batch_outs = execution_function(iterator)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\", line 98, in execution_function\n",
      "    distributed_function(input_fn))\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 568, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 632, in _call\n",
      "    return self._stateless_fn(*args, **kwds)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 2363, in __call__\n",
      "    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1611, in _filtered_call\n",
      "    self.captured_inputs)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1692, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager))\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 545, in call\n",
      "    ctx=ctx)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\", line 67, in quick_execute\n",
      "    six.raise_from(core._status_to_exception(e.code, message), None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "tensorflow.python.framework.errors_impl.ResourceExhaustedError:  OOM when allocating tensor with shape[32,128,112,112] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[node model/block2_conv2/Conv2D (defined at <ipython-input-5-c0d490c953fa>:56) ]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      " [Op:__inference_distributed_function_2147]\n",
      "\n",
      "Function call stack:\n",
      "distributed_function\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ResourceExhaustedError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3360, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1193, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2895, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3072, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3282, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1211, in structured_traceback\n",
      "    chained_exceptions_tb_offset)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\diego\\anaconda3\\envs\\env4\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "# Deep Tuning\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "networks = ['vgg16', 'vgg19']\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "for network in networks:\n",
    "    print(f\"---------------{network}---------------\")\n",
    "    \n",
    "    img_size = 299 if network == 'inceptionv3' else 224\n",
    "    img_shape = (img_size, img_size, 3)\n",
    "    print(img_size)\n",
    "\n",
    "    model_name = f\"{network}_kaggle_enrique_voluntarios_2\"\n",
    "    base_model, model = build_model(network, img_shape, True)\n",
    "\n",
    "    model.load_weights(f'{model_name}.keras')\n",
    "    model_name = f\"{network}_kaggle_enrique_voluntarios_2_deep_tuning\"\n",
    "    \n",
    "    X_train_preprocessed, y_train, X_val_preprocessed, y_val, X_test_preprocessed, y_test, X_test = set_data(network, img_size)\n",
    "        \n",
    "    is_data_augmentation = True\n",
    "    model, history = train(model, network, f'{model_name}.keras', X_train_preprocessed, y_train, X_val_preprocessed, y_val, 50, is_data_augmentation)\n",
    "    \n",
    "    model.load_weights(f'{model_name}.keras')\n",
    "\n",
    "    show_metrics(history)\n",
    "    evaluate_model(model, X_test_preprocessed, y_test)\n",
    "    save_model(model_name)\n",
    "\n",
    "    # Limpiar memoria\n",
    "    del model, base_model, history\n",
    "    del X_train_preprocessed, y_train, X_val_preprocessed, y_val, X_test_preprocessed, y_test\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6700f7a5-9087-4b05-b672-0105e33e79eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 1562\n"
     ]
    }
   ],
   "source": [
    "# import gc\n",
    "# import tensorflow as tf\n",
    "\n",
    "# tf.get_logger().setLevel('ERROR')  # opcional\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# networks = ['vgg16', 'vgg19', 'resnet50', 'inceptionv3']\n",
    "# for network in networks:\n",
    "    \n",
    "#     print(f\"---------------{network}---------------\")\n",
    "    \n",
    "#     img_size = 299 if network == 'inceptionv3' else 224\n",
    "#     img_shape = (img_size, img_size, 3)\n",
    "\n",
    "#     base_model, model = build_model(network, img_shape)\n",
    "\n",
    "#     X_train_preprocessed, y_train, X_val_preprocessed, y_val, X_test_preprocessed, y_test, X_test = set_data(network, img_size)\n",
    "        \n",
    "#     is_data_augmentation = True\n",
    "#     model_name = f\"best_model_data_augmentation_kaggle_2_{network}\" if is_data_augmentation == True else f\"mejor_modelo_kaggle_2_{network}\"\n",
    "#     model, history = train(model, network, model_name, X_train_preprocessed, y_train, X_val_preprocessed, y_val, 5, is_data_augmentation)\n",
    "\n",
    "#     show_metrics(history)\n",
    "#     evaluate_model(model, X_test_preprocessed, y_test)\n",
    "#     save_model(model_name)\n",
    "\n",
    "#     # Limpiar memoria\n",
    "#     del model, base_model, history\n",
    "#     del X_train_preprocessed, y_train, X_val_preprocessed, y_val, X_test_preprocessed, y_test\n",
    "#     tf.keras.backend.clear_session()\n",
    "#     gc.collect()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
